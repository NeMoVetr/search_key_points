# Проект «Поиск и сопоставление ключевых точек на изображениях»

> *Authors: your-name-here (fill in)*
> *License: MIT (измените при необходимости)*

---

## Оглавление
1. [Описание проекта](#описание-проекта)
2. [Ключевые возможности](#ключевые-возможности)
3. [Структура репозитория](#структура-репозитория)
4. [Установка](#установка)
5. [Быстрый старт](#быстрый-старт)
6. [Архитектура и детали реализации](#архитектура-и-детали-реализации)
7. [Формат выходных данных](#формат-выходных-данных)
8. [Настройка эксперимента](#настройка-эксперимента)
9. [Скрипты и входные параметры](#скрипты-и-входные-параметры)
10. [FAQ](#faq)
11. [Контрибьютинг](#контрибьютинг)

---

## Описание проекта
Данный проект предназначен для **сравнительного анализа алгоритмов обнаружения и сопоставления ключевых точек** на изображениях. 

Программа:
* генерирует искажённые версии исходных изображений (изменение яркости, контраста, масштаба, поворот, размытие);
* для каждой пары изображений вычисляет метрики качества (число совпадений, коэффициент удачных соответствий, косинусная схожесть и др.);
* сохраняет отчёты в `.csv`, изображения с наложенными ключевыми точками, а также наглядные графики и гистограммы.

Алгоритмы, присутствующие «из коробки»  
| Детекторы                                    | Дескрипторы | Матчеры                                       |
|-----------------------------------------------|-------------|-----------------------------------------------|
| ORB, FAST, KAZE, AKAZE, AGAST, GFTT, MSER, SIFT | ORB, BRISK  | BFMatcher (L2, Hamming2, L2SQR), FLANN (LSH, KD-Tree, KMeans) |

При желании список методов легко расширяется — достаточно дополнить функцию `initialize_methods` внутри `initializer.py`.

---

## Ключевые возможности
* Генерация датасета искажений различного типа и интенсивности (`generegate_dataset.py`);
* Массовая параллельная обработка изображений с использованием всех доступных ядер CPU (`multiprocessing.Pool`);
* Гибкая система метрик: количество и доля «хороших» совпадений, средняя длина вектора/косинусная схожесть дескрипторов, время вычисления и др.;
* Автоматическое построение графиков и гистограмм (`create_visualisation.py`);
* Четкая структура выходных файлов (`/result`, `/new_images`).

---

## Структура репозитория
```
search_key_points/
├── image_*               # Папки с исходными изображениями (image_1 … image_7)
│   ├── original_image.jpg
│   └── compared_image.jpg (опционально)
├── create_visualisation.py
├── generegate_dataset.py
├── initializer.py
├── search_points.py      # Главная точка входа
├── __pycache__/
└── README.md             # Вы читаете этот файл
```
Дополнительные директории (создаются автоматически):
* `result/` — csv-отчёты и визуализации;
* `new_images/` — изображения с отмеченными совпадениями ключевых точек.

---

## Установка
1. Клонируйте репозиторий или скопируйте исходный код в удобное место:
```bash
# Linux / macOS
git clone <repo-url>
cd search_key_points
```
2. Создайте и активируйте виртуальное окружение (опционально, но рекомендуется):
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```
3. Установите зависимости:
```bash
pip install -r requirements.txt
```
Если файл `requirements.txt` ещё не создан, используйте список минимальных пакетов:
```bash
pip install opencv-python numpy matplotlib scikit-learn
```

Тестировалось на **Python 3.9+**.

---

## Быстрый старт
1. Поместите набор папок `image_1/ … image_n/` рядом со скриптом `search_points.py`. В каждой папке должен лежать хотя бы `original_image.jpg`.  
2. (Опционально) Добавьте `compared_image.jpg`, если необходимо сравнить два конкретных снимка.
3. Запустите основной скрипт:
```bash
python search_points.py
```
По завершении работы появятся:
* `result/saved_points.csv` — число найденных точек для каждой комбинации методов;
* `result/saved_data.csv` — агрегированные метрики;
* `result/Гистограммы/` и другие поддиректории с графиками;
* `new_images/` — визуализации совпадений.

---

## Архитектура и детали реализации
| Файл | Ответственность |
|------|-----------------|
| `search_points.py` | Организация полного цикла экспериментов, параллельная обработка, агрегация метрик |
| `initializer.py` | Создание объектов детекторов, дескрипторов и матчеров OpenCV |
| `generegate_dataset.py` | Генерация искажённых версий исходного изображения (яркость, контраст, угол, масштаб, размытие) |
| `create_visualisation.py` | Построение гистограмм и линий тренда по результатам эксперимента |

Взаимодействие реализовано в следующем порядке:
```
search_points.py
 ├─ initialize_methods()           # создание алгоритмов
 ├─ load_image()                   # генерация искажений
 ├─ evaluate_methods()             # вычисление метрик для одной пары изображений
 │    ├─ lowes_ratio_test()
 │    ├─ calculate_mean_matching_distance()
 │    └─ calculate_cosine_similarity()
 ├─ aggregate_metrics()            # усреднение результатов
 └─ plot_metrics()                 # визуализация
```

### Ключевые метрики
| Метрика | Описание |
|---------|----------|
| **num_matches** | Общее количество сопоставленных точек |
| **matching_ratio** | Доля «хороших» совпадений по критерию Lowe (ratio-test 0.8) |
| **found_points_ratio** | Отношение числа найденных точек в первом изображении к числу вo втором |
| **matching_distance** | Среднее евклидово расстояние между парой точек |
| **cosine_similarity** | Средняя косинусная схожесть дескрипторов |
| **execution_time** | Среднее время вычисления для комбинации методов |

---

## Формат выходных данных
| Файл | Формат | Содержимое |
|------|--------|-----------|
| `result/saved_points.csv` | CSV | `Комбинация дескриптор + алгоритм`, `Количество найденных точек` |
| `result/saved_data.csv`   | CSV | Полный набор агрегированных метрик (см. таблицу выше) |
| `result/Гистограммы/*.png` | PNG | Гистограммы для каждой метрики |
| `result/<Категория>/**/*.png` | PNG | Графики изменения метрик в зависимости от степени искажения |
| `new_images/*.png`        | PNG | Две картинки, склеенные по горизонтали с отображением линий-мачингов |

---

## Настройка эксперимента
Все основные параметры вынесены в начало `search_points.py`:
```python
filename_1 = "original_image.jpg"
filename_2 = "compared_image.jpg"  # оставить пустым, если нужно сравнить сгенерированные искажения
folder_name = "image_"             # шаблон для имён директорий
folders = [(f"{folder_name}{i}", filename_1, filename_2) for i in range(1, 8)]
```
Измените список `folders`, чтобы увеличить/уменьшить количество обрабатываемых наборов.

---

## Скрипты и входные параметры
| Скрипт | Аргументы | Назначение |
|--------|-----------|------------|
| `search_points.py` | — | Главный входной скрипт; запускает полный пайплайн |
| `generegate_dataset.py` | `dataset(image_path)` | Возвращает словарь искажённых изображений |
| `create_visualisation.py` | `plot_metrics(aggregated_metrics, out_dir)` | Строит графики по метрикам |

---

## FAQ
**Q:** Почему программа работает медленно?  
**A:** Убедитесь, что используется свежая сборка OpenCV с оптимизациями, а также достаточное количество ядер CPU. При необходимости уменьшите число обрабатываемых изображений.

**Q:** Как добавить новый детектор/дескриптор?  
**A:** Допишите соответствующий объект в словарь `detectors` или `descriptors` функции `initialize_methods`.

---

## Контрибьютинг
1. Форкните репозиторий и создайте ветку `feature/<название>`
2. Оформите изменения согласно PEP-8 и добавьте необходимые docstring-и
3. Создайте Pull Request — буду рад улучшениям!
